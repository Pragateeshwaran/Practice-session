{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "randint(low=0, high, size, \\*, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "\n",
      "Returns a tensor filled with random integers generated uniformly\n",
      "between :attr:`low` (inclusive) and :attr:`high` (exclusive).\n",
      "\n",
      "The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "\n",
      ".. note::\n",
      "    With the global dtype default (``torch.float32``), this function returns\n",
      "    a tensor with dtype ``torch.int64``.\n",
      "\n",
      "Args:\n",
      "    low (int, optional): Lowest integer to be drawn from the distribution. Default: 0.\n",
      "    high (int): One above the highest integer to be drawn from the distribution.\n",
      "    size (tuple): a tuple defining the shape of the output tensor.\n",
      "\n",
      "Keyword args:\n",
      "    generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "    out (Tensor, optional): the output tensor.\n",
      "    dtype (`torch.dtype`, optional) - the desired data type of returned tensor. Default: if ``None``,\n",
      "        this function returns a tensor with dtype ``torch.int64``.\n",
      "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "        Default: ``torch.strided``.\n",
      "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "        Default: if ``None``, uses the current device for the default tensor type\n",
      "        (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
      "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "    requires_grad (bool, optional): If autograd should record operations on the\n",
      "        returned tensor. Default: ``False``.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> torch.randint(3, 5, (3,))\n",
      "    tensor([4, 3, 4])\n",
      "\n",
      "\n",
      "    >>> torch.randint(10, (2, 2))\n",
      "    tensor([[0, 2],\n",
      "            [5, 5]])\n",
      "\n",
      "\n",
      "    >>> torch.randint(3, 10, (2, 2))\n",
      "    tensor([[4, 5],\n",
      "            [6, 7]])\n",
      "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "torch.randint??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 10, 11, 11],\n",
       "        [10, 10, 10, 11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(low= 10, high= 13, size=(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "stack(tensors, dim=0, *, out=None) -> Tensor\n",
      "\n",
      "Concatenates a sequence of tensors along a new dimension.\n",
      "\n",
      "All tensors need to be of the same size.\n",
      "\n",
      ".. seealso::\n",
      "\n",
      "    :func:`torch.cat` concatenates the given sequence along an existing dimension.\n",
      "\n",
      "Arguments:\n",
      "    tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "    dim (int, optional): dimension to insert. Has to be between 0 and the number\n",
      "        of dimensions of concatenated tensors (inclusive). Default: 0\n",
      "\n",
      "Keyword args:\n",
      "    out (Tensor, optional): the output tensor.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.randn(2, 3)\n",
      "    >>> x\n",
      "    tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "            [ 0.2303, -1.1229, -0.1863]])\n",
      "    >>> x = torch.stack((x, x)) # same as torch.stack((x, x), dim=0)\n",
      "    >>> x\n",
      "    tensor([[[ 0.3367,  0.1288,  0.2345],\n",
      "             [ 0.2303, -1.1229, -0.1863]],\n",
      "\n",
      "            [[ 0.3367,  0.1288,  0.2345],\n",
      "             [ 0.2303, -1.1229, -0.1863]]])\n",
      "    >>> x.size()\n",
      "    torch.Size([2, 2, 3])\n",
      "    >>> x = torch.stack((x, x), dim=1)\n",
      "    tensor([[[ 0.3367,  0.1288,  0.2345],\n",
      "             [ 0.3367,  0.1288,  0.2345]],\n",
      "\n",
      "            [[ 0.2303, -1.1229, -0.1863],\n",
      "             [ 0.2303, -1.1229, -0.1863]]])\n",
      "    >>> x = torch.stack((x, x), dim=2)\n",
      "    tensor([[[ 0.3367,  0.3367],\n",
      "             [ 0.1288,  0.1288],\n",
      "             [ 0.2345,  0.2345]],\n",
      "\n",
      "            [[ 0.2303,  0.2303],\n",
      "             [-1.1229, -1.1229],\n",
      "             [-0.1863, -0.1863]]])\n",
      "    >>> x = torch.stack((x, x), dim=-1)\n",
      "    tensor([[[ 0.3367,  0.3367],\n",
      "             [ 0.1288,  0.1288],\n",
      "             [ 0.2345,  0.2345]],\n",
      "\n",
      "            [[ 0.2303,  0.2303],\n",
      "             [-1.1229, -1.1229],\n",
      "             [-0.1863, -0.1863]]])\n",
      "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.stack??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6927, 0.5565],\n",
       "        [0.7286, 0.7987],\n",
       "        [0.4266, 0.5485]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  \n",
    "var = torch.rand(3,2)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6927, 0.5565],\n",
       "         [0.7286, 0.7987],\n",
       "         [0.4266, 0.5485]],\n",
       "\n",
       "        [[0.6927, 0.5565],\n",
       "         [0.7286, 0.7987],\n",
       "         [0.4266, 0.5485]],\n",
       "\n",
       "        [[0.6927, 0.5565],\n",
       "         [0.7286, 0.7987],\n",
       "         [0.4266, 0.5485]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_1 = torch.stack((var, var, var))\n",
    "stacked_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6927, 0.6927, 0.6927],\n",
       "         [0.5565, 0.5565, 0.5565]],\n",
       "\n",
       "        [[0.7286, 0.7286, 0.7286],\n",
       "         [0.7987, 0.7987, 0.7987]],\n",
       "\n",
       "        [[0.4266, 0.4266, 0.4266],\n",
       "         [0.5485, 0.5485, 0.5485]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_2 = torch.stack((var, var, var), dim= 2)\n",
    "stacked_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
